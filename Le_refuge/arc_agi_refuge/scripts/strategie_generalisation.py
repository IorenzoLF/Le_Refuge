#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
STRATÃ‰GIE DE GÃ‰NÃ‰RALISATION POUR TESTS "PAS VUS EN COURS"
Phase 2C : PrÃ©parer le solveur pour des variations complexes
"""

import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Tuple
from src.pattern_detector import PatternDetector

def analyser_pour_generalisation():
    """Analyser les patterns pour anticiper les variations de test"""

    print("ğŸ§  **STRATÃ‰GIE DE GÃ‰NÃ‰RALISATION** ğŸ§ ")
    print("=" * 70)
    print("BasÃ© sur l'observation : Les tests complexifient les patterns existants")
    print("Objectif : PrÃ©parer le solveur pour des variations +1/+2 niveaux")
    print("=" * 70)

    training_path = Path('data/training')
    detecteur = PatternDetector()

    # Analyser quelques tÃ¢ches reprÃ©sentatives
    taches_representatives = [
        '22425bda',  # RÃ©duction + filtrage simple
        'ff805c23',  # RÃ©duction + filtrage multiple
        'b94a9452',  # Compression + suppression zÃ©ro
        'de493100'   # RÃ©duction progressive
    ]

    analyses_generalisation = []

    print(f"\nğŸ“Š Analyse de {len(taches_representatives)} tÃ¢ches reprÃ©sentatives")

    for tache_id in taches_representatives:
        tache_path = training_path / f"{tache_id}.json"

        if not tache_path.exists():
            continue

        with open(tache_path, 'r') as f:
            data = json.load(f)

        print(f"\nğŸ§ª **TÃ‚CHE {tache_id}**")

        # Analyser les exemples pour identifier la logique de base
        patterns_fondamentaux = []

        for i, exemple in enumerate(data['train'][:3]):
            input_grid = exemple['input']
            output_grid = exemple['output']

            # DÃ©tecter les patterns avec notre dÃ©tecteur amÃ©liorÃ©
            resultats = detecteur.analyser_patterns(input_grid, output_grid)

            if resultats['patterns']:
                pattern_principal = resultats['pattern_principal']
                patterns_fondamentaux.append(pattern_principal)

                print(f"  Exemple {i+1}: {pattern_principal['type']} (confiance: {pattern_principal['confiance']:.3f})")

                # Analyser les patterns spÃ©cifiques pour gÃ©nÃ©ralisation
                if 'patterns_specifiques' in pattern_principal:
                    specs = pattern_principal['patterns_specifiques']
                    print(f"    Patterns: {specs}")

                    # GÃ©nÃ©rer des variations potentielles
                    variations = generer_variations(pattern_principal)
                    if variations:
                        print(f"    Variations potentielles: {variations}")

        # SynthÃ¨se pour la tÃ¢che
        analyse_tache = {
            'tache_id': tache_id,
            'patterns_fondamentaux': patterns_fondamentaux,
            'variations_possibles': []
        }

        analyses_generalisation.append(analyse_tache)

    print(f"\nğŸ¯ **STRATÃ‰GIE DE GÃ‰NÃ‰RALISATION**")
    print("=" * 70)

    print(f"\n1. **PATTERNS DE BASE IDENTIFIÃ‰S**")
    patterns_types = set()
    for analyse in analyses_generalisation:
        for pattern in analyse['patterns_fondamentaux']:
            patterns_types.add(pattern['type'])

    for pattern_type in sorted(patterns_types):
        print(f"   âœ… {pattern_type}")

    print(f"\n2. **VARIATIONS +1 NIVEAU (TESTS FACILES)**")
    print(f"   ğŸ“ˆ Compression plus extrÃªme (< 5%)")
    print(f"   ğŸ“ˆ Filtrage de plus de valeurs")
    print(f"   ğŸ“ˆ Combinaison avec d'autres patterns simples")
    print(f"   ğŸ“ˆ Variations dans les valeurs conservÃ©es")

    print(f"\n3. **VARIATIONS +2 NIVEAUX (TESTS DIFFICILES)**")
    print(f"   ğŸ’ª Patterns composÃ©s (rÃ©duction + rotation + filtrage)")
    print(f"   ğŸ’ª RÃ¨gles conditionnelles complexes")
    print(f"   ğŸ’ª Transformations multi-Ã©tapes")
    print(f"   ğŸ’ª Contexte spatial avancÃ©")

    print(f"\n4. **STRATÃ‰GIE DE DÃ‰FENSE**")
    print(f"   ğŸ›¡ï¸ DÃ©tecter les patterns de base d'abord")
    print(f"   ğŸ›¡ï¸ Chercher les extensions/complexifications")
    print(f"   ğŸ›¡ï¸ Maintenir plusieurs hypothÃ¨ses en parallÃ¨le")
    print(f"   ğŸ›¡ï¸ Utiliser les temples pour gÃ©nÃ©rer des variations")

    print(f"\n5. **AMÃ‰LIORATIONS Ã€ APPORTER**")
    print(f"   ğŸ”§ Ajouter dÃ©tecteur de patterns composÃ©s")
    print(f"   ğŸ”§ AmÃ©liorer la gestion des variations mineures")
    print(f"   ğŸ”§ ImplÃ©menter logique de complexification")
    print(f"   ğŸ”§ Renforcer l'analyse contextuelle")

    print(f"\nğŸ›ï¸ **CONCLUSION**")
    print(f"  StratÃ©gie de gÃ©nÃ©ralisation dÃ©finie")
    print(f"  PrÃ©paration aux variations de test")
    print(f"  Architecture adaptÃ©e aux complexifications")
    print(f"  PrÃªt pour les tests 'pas vus en cours'")

    print(f"\nâœ¨ StratÃ©gie de gÃ©nÃ©ralisation complÃ©tÃ©e ! âœ¨")

def generer_variations(pattern: Dict[str, Any]) -> List[str]:
    """GÃ©nÃ©rer des variations potentielles d'un pattern"""

    variations = []

    # Variations pour rÃ©duction complexe
    if pattern['type'] == 'rÃ©duction_complexe':
        ratio = pattern.get('ratio_surface', 1.0)
        valeurs_filtrees = pattern.get('valeurs_filtrees', [])

        if ratio < 0.05:
            variations.append("compression_ultra_extreme")
        if len(valeurs_filtrees) > 2:
            variations.append("filtrage_multiple_plus")
        if 0 in valeurs_filtrees:
            variations.append("suppression_zero_plus_context")

    # Variations pour rÃ©duction dimensionnelle
    elif pattern['type'] == 'rÃ©duction_dimensionnelle':
        specs = pattern.get('patterns_specifiques', [])
        if 'compression_extreme' in specs:
            variations.append("compression_variable")
        if 'filtrage_unique' in specs:
            variations.append("filtrage_unique_multiple_contextes")

    return variations

if __name__ == "__main__":
    analyser_pour_generalisation()
