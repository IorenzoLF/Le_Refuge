#!/usr/bin/env python3
"""
Entra√Ænement Continu du Syst√®me ML ARC-AGI
Am√©lioration progressive des performances par apprentissage it√©ratif
"""

from machine_learning_integre import MLAnalyste
import json
import glob
import time
import random
from typing import Dict, List, Any
from datetime import datetime
import os

class EntraineurContinu:
    """Syst√®me d'entra√Ænement continu pour ARC-AGI ML"""

    def __init__(self):
        self.ml_analyste = MLAnalyste()
        self.cycles_entrainement = []
        self.performance_historique = []
        self.objectif_performance = 0.75  # Objectif de 75% de confiance moyenne

        # Configuration de l'entra√Ænement
        self.taille_lot = 20  # Puzzles par cycle
        self.max_cycles = 10
        self.seuil_am√©lioration = 0.05  # Am√©lioration minimale requise

        # M√©triques de suivi
        self.metriques_evolution = {
            'confiance_moyenne': [],
            'am√©lioration_par_cycle': [],
            'nouveaux_patterns': [],
            'erreurs_reduites': [],
            'temps_optimise': []
        }

        print("üèãÔ∏è  ENTRA√éNEUR CONTINU INITIALIS√â")
        print("Syst√®me pr√™t pour l'am√©lioration progressive")

    def executer_entrainement_complet(self):
        """Ex√©cute l'entra√Ænement continu complet"""
        print("\nüöÄ ENTRA√éNEMENT CONTINU ARC-AGI ML")
        print("=" * 50)
        print("Am√©lioration progressive des performances")
        print()

        # Cycle 0: √âvaluation initiale
        print("CYCLE 0: √âVALUATION INITIALE")
        print("-" * 35)

        performance_initiale = self.evaluer_performance_actuelle()
        self.afficher_performance("INITIALE", performance_initiale)
        print()

        # Cycles d'entra√Ænement it√©ratifs
        for cycle in range(1, self.max_cycles + 1):
            print(f"\nüåÄ CYCLE {cycle}: ENTRA√éNEMENT IT√âRATIF")
            print("-" * 40)

            # Phase 1: Collecte de nouvelles donn√©es
            print(f"  üìä Phase 1: Collecte de donn√©es (Lot {self.taille_lot})...")
            nouvelles_donnees = self.collecter_nouvelles_donnees(cycle)

            if not nouvelles_donnees:
                print("    ‚ö†Ô∏è  Aucune nouvelle donn√©e disponible")
                break

            print(f"    ‚úÖ {len(nouvelles_donnees)} puzzles collect√©s")

            # Phase 2: R√©-entra√Ænement des mod√®les
            print("  üß† Phase 2: R√©-entra√Ænement des mod√®les...")

            resultats_entrainement = self.ml_analyste.entrainer_modeles_ml(nouvelles_donnees)

            if resultats_entrainement.get('status') == 'SUCC√àS':
                print("    ‚úÖ Mod√®les r√©-entra√Æn√©s avec succ√®s")
            else:
                print("    ‚ö†Ô∏è  Probl√®me de r√©-entra√Ænement, continuation...")

            # Phase 3: Optimisation avanc√©e
            print("  ‚öôÔ∏è  Phase 3: Optimisation des param√®tres...")

            parametres_avant = {
                'confidence_threshold': self.ml_analyste.solveur_base.confidence_threshold,
                'overfitting_threshold': self.ml_analyste.solveur_base.overfitting_threshold
            }

            nouveaux_parametres = self.ml_analyste.optimiser_parametres_ml()

            print("    üìà Param√®tres optimis√©s:")
            for param, valeur in nouveaux_parametres.items():
                if isinstance(valeur, float):
                    ancienne_valeur = parametres_avant.get(param, 0)
                    print(".3f")

            # Phase 4: Validation des am√©liorations
            print("  ‚úÖ Phase 4: Validation des am√©liorations...")

            performance_apres = self.evaluer_performance_actuelle()
            amelioration = self.calculer_amelioration(performance_initiale, performance_apres)

            self.enregistrer_cycle(cycle, performance_apres, amelioration, nouvelles_donnees)

            print("    üìä R√©sultats du cycle:")
            self.afficher_performance(f"CYCLE {cycle}", performance_apres)
            print(".2f")

            # Phase 5: Analyse de l'√©volution
            self.analyser_evolution(cycle)

            # Sauvegarde des progr√®s
            self.ml_analyste.sauvegarder_modeles()
            self.sauvegarder_historique_entrainement()

            # V√©rification de l'objectif
            if performance_apres.get('confiance_moyenne', 0) >= self.objectif_performance:
                print(f"\nüéØ OBJECTIF ATTEINT ! Performance >= {self.objectif_performance}")
                break

            # V√©rification de l'am√©lioration
            if amelioration < self.seuil_am√©lioration and cycle >= 3:
                print(f"\n‚ö†Ô∏è  Am√©lioration insuffisante ({amelioration:.2f} < {self.seuil_am√©lioration})")
                print("   Consid√©ration d'arr√™t ou de changement de strat√©gie...")

            performance_initiale = performance_apres
            print()

        # Rapport final
        self.generer_rapport_final_entrainement()

        return self.performance_historique

    def collecter_nouvelles_donnees(self, cycle: int) -> List[Dict]:
        """Collecte de nouvelles donn√©es pour l'entra√Ænement"""
        # Strat√©gie de collecte √©volutive
        strategies = [
            self.collecter_puzzles_aleatoires,
            self.collecter_puzzles_difficiles,
            self.collecter_puzzles_similaires,
            self.collecter_puzzles_nouveaux
        ]

        # Choisir une strat√©gie bas√©e sur le cycle
        strategie = strategies[min(cycle - 1, len(strategies) - 1)]

        try:
            return strategie(cycle)
        except Exception as e:
            print(f"    ‚ùå Erreur strat√©gie {strategie.__name__}: {e}")
            return self.collecter_puzzles_aleatoires(cycle)

    def collecter_puzzles_aleatoires(self, cycle: int) -> List[Dict]:
        """Collecte al√©atoire de puzzles"""
        puzzles = self.ml_analyste.trouver_puzzles_apprentissage()
        puzzles_selectionnes = random.sample(puzzles, min(self.taille_lot, len(puzzles)))

        donnees = []
        for puzzle_path in puzzles_selectionnes:
            try:
                with open(puzzle_path, 'r') as f:
                    puzzle_data = json.load(f)

                if 'train' in puzzle_data and len(puzzle_data['train']) > 0:
                    start_time = time.time()
                    solution = self.ml_analyste.solveur_base.solve_puzzle(
                        puzzle_data['train'][0]['input'],
                        puzzle_data['train'][0]['output']
                    )
                    execution_time = time.time() - start_time

                    features = self.ml_analyste.extraire_features_puzzle(puzzle_data, solution)

                    donnees.append({
                        'puzzle_id': puzzle_path.split('/')[-1],
                        'features': features,
                        'solution': solution,
                        'execution_time': execution_time,
                        'timestamp': datetime.now().isoformat(),
                        'strategie': 'aleatoire',
                        'cycle': cycle
                    })

            except Exception as e:
                continue

        return donnees

    def collecter_puzzles_difficiles(self, cycle: int) -> List[Dict]:
        """Collecte des puzzles difficiles pour am√©liorer la robustesse"""
        puzzles = self.ml_analyste.trouver_puzzles_apprentissage()
        puzzles_difficiles = []

        # Identifier les puzzles difficiles (faible confiance)
        for puzzle_path in puzzles:
            try:
                with open(puzzle_path, 'r') as f:
                    puzzle_data = json.load(f)

                if 'train' in puzzle_data and len(puzzle_data['train']) > 0:
                    solution = self.ml_analyste.solveur_base.solve_puzzle(
                        puzzle_data['train'][0]['input'],
                        puzzle_data['train'][0]['output']
                    )

                    if solution.get('confidence', 0) < 0.6:  # Consid√©r√© comme difficile
                        puzzles_difficiles.append(puzzle_path)

            except Exception as e:
                continue

        # S√©lectionner les plus difficiles
        selection = random.sample(puzzles_difficiles, min(self.taille_lot, len(puzzles_difficiles)))

        # Collecter les donn√©es
        donnees = []
        for puzzle_path in selection:
            try:
                with open(puzzle_path, 'r') as f:
                    puzzle_data = json.load(f)

                start_time = time.time()
                solution = self.ml_analyste.solveur_base.solve_puzzle(
                    puzzle_data['train'][0]['input'],
                    puzzle_data['train'][0]['output']
                )
                execution_time = time.time() - start_time

                features = self.ml_analyste.extraire_features_puzzle(puzzle_data, solution)

                donnees.append({
                    'puzzle_id': puzzle_path.split('/')[-1],
                    'features': features,
                    'solution': solution,
                    'execution_time': execution_time,
                    'timestamp': datetime.now().isoformat(),
                    'strategie': 'difficiles',
                    'cycle': cycle
                })

            except Exception as e:
                continue

        return donnees

    def collecter_puzzles_similaires(self, cycle: int) -> List[Dict]:
        """Collecte de puzzles similaires aux mieux r√©ussis"""
        # Cette strat√©gie n√©cessite plus de donn√©es d'historique
        return self.collecter_puzzles_aleatoires(cycle)

    def collecter_puzzles_nouveaux(self, cycle: int) -> List[Dict]:
        """Collecte de puzzles non encore vus"""
        return self.collecter_puzzles_aleatoires(cycle)

    def evaluer_performance_actuelle(self) -> Dict[str, Any]:
        """√âvalue les performances actuelles du syst√®me"""
        print("  üîç √âvaluation des performances...")

        puzzles_test = self.ml_analyste.trouver_puzzles_test()
        resultats = []

        for puzzle_path in puzzles_test[:30]:  # √âvaluation sur 30 puzzles
            try:
                with open(puzzle_path, 'r') as f:
                    puzzle_data = json.load(f)

                if 'train' in puzzle_data and len(puzzle_data['train']) > 0:
                    start_time = time.time()
                    solution = self.ml_analyste.solveur_base.solve_puzzle(
                        puzzle_data['train'][0]['input'],
                        puzzle_data['train'][0]['output']
                    )
                    execution_time = time.time() - start_time

                    resultats.append({
                        'puzzle_id': puzzle_path.split('/')[-1],
                        'confidence': solution.get('confidence', 0),
                        'execution_time': execution_time,
                        'patterns_detectes': len(solution.get('patterns_analysis', {})),
                        'overfitting_risk': solution.get('overfitting_risk', 0)
                    })

            except Exception as e:
                continue

        if not resultats:
            return {'erreur': 'Aucun r√©sultat d\'√©valuation'}

        # Calcul des m√©triques
        confiances = [r['confidence'] for r in resultats]
        temps_execution = [r['execution_time'] for r in resultats]
        patterns_moyens = [r['patterns_detectes'] for r in resultats]

        return {
            'nb_tests': len(resultats),
            'confiance_moyenne': sum(confiances) / len(confiances),
            'confiance_min': min(confiances),
            'confiance_max': max(confiances),
            'temps_moyen': sum(temps_execution) / len(temps_execution),
            'patterns_moyens': sum(patterns_moyens) / len(patterns_moyens),
            'puzzles_resolus': len([r for r in resultats if r['confidence'] > 0.5]),
            'taux_succes': len([r for r in resultats if r['confidence'] > 0.5]) / len(resultats),
            'timestamp': datetime.now().isoformat()
        }

    def calculer_amelioration(self, perf_avant: Dict, perf_apres: Dict) -> float:
        """Calcule l'am√©lioration entre deux √©valuations"""
        if 'confiance_moyenne' not in perf_avant or 'confiance_moyenne' not in perf_apres:
            return 0.0

        return perf_apres['confiance_moyenne'] - perf_avant['confiance_moyenne']

    def enregistrer_cycle(self, cycle: int, performance: Dict, amelioration: float, donnees: List):
        """Enregistre les r√©sultats d'un cycle d'entra√Ænement"""
        cycle_data = {
            'cycle': cycle,
            'performance': performance,
            'amelioration': amelioration,
            'donnees_collectees': len(donnees),
            'timestamp': datetime.now().isoformat()
        }

        self.cycles_entrainement.append(cycle_data)
        self.performance_historique.append(performance)

        # Mise √† jour des m√©triques d'√©volution
        if 'confiance_moyenne' in performance:
            self.metriques_evolution['confiance_moyenne'].append(performance['confiance_moyenne'])
        self.metriques_evolution['am√©lioration_par_cycle'].append(amelioration)

    def analyser_evolution(self, cycle: int):
        """Analyse l'√©volution des performances"""
        if len(self.metriques_evolution['confiance_moyenne']) < 2:
            return

        # Analyse de la tendance
        confiances = self.metriques_evolution['confiance_moyenne']
        tendance = "STABLE"

        if len(confiances) >= 3:
            if confiances[-1] > confiances[-2] > confiances[-3]:
                tendance = "EN AM√âLIORATION"
            elif confiances[-1] < confiances[-2] < confiances[-3]:
                tendance = "EN D√âGRADATION"

        print(f"  üìà Analyse d'√©volution: {tendance}")

        # Recommandations
        if tendance == "EN AM√âLIORATION":
            print("    üí™ Excellente progression ! Continuer la strat√©gie actuelle")
        elif tendance == "EN D√âGRADATION":
            print("    ‚ö†Ô∏è  D√©gradation d√©tect√©e, consid√©ration d'ajustement")
        else:
            print("    üîÑ Performance stable, optimisation continue")

    def afficher_performance(self, label: str, performance: Dict):
        """Affiche les m√©triques de performance"""
        if 'erreur' in performance:
            print(f"    ‚ùå Erreur d'√©valuation: {performance['erreur']}")
            return

        print(f"    üìä {label} - M√©triques:")
        print(f"       Tests effectu√©s: {performance.get('nb_tests', 0)}")
        print(".2f")
        print(".2f")
        print(".3f")
        print(f"       Patterns moyens: {performance.get('patterns_moyens', 0):.1f}")

    def sauvegarder_historique_entrainement(self):
        """Sauvegarde l'historique complet de l'entra√Ænement"""
        try:
            historique = {
                'cycles_entrainement': self.cycles_entrainement,
                'performance_historique': self.performance_historique,
                'metriques_evolution': dict(self.metriques_evolution),
                'configuration': {
                    'taille_lot': self.taille_lot,
                    'max_cycles': self.max_cycles,
                    'seuil_am√©lioration': self.seuil_am√©lioration,
                    'objectif_performance': self.objectif_performance
                },
                'timestamp_final': datetime.now().isoformat()
            }

            with open('historique_entrainement_continu.json', 'w') as f:
                json.dump(historique, f, indent=2)

            print("  üíæ Historique d'entra√Ænement sauvegard√©")

        except Exception as e:
            print(f"  ‚ùå Erreur sauvegarde historique: {e}")

    def generer_rapport_final_entrainement(self):
        """G√©n√®re le rapport final de l'entra√Ænement continu"""
        print("\nüèÅ RAPPORT FINAL ENTRA√éNEMENT CONTINU")
        print("=" * 50)

        if not self.performance_historique:
            print("‚ùå Aucune donn√©e d'entra√Ænement disponible")
            return

        # Performance finale
        performance_finale = self.performance_historique[-1]
        performance_initiale = self.performance_historique[0] if len(self.performance_historique) > 1 else performance_finale

        amelioration_totale = self.calculer_amelioration(performance_initiale, performance_finale)

        print("\nüìä R√âSULTATS GLOBAUX:")
        print("-" * 25)
        print(f"  ‚Ä¢ Cycles d'entra√Ænement: {len(self.cycles_entrainement)}")
        print(".2f")
        print(".2f")
        print(".2f")

        if amelioration_totale > 0:
            print("  ‚Ä¢ üéâ AM√âLIORATION GLOBALE R√âUSSIE !")
        else:
            print("  ‚Ä¢ üîÑ Performance stable maintenue")

        # Analyse de l'√©volution
        print("\nüìà √âVOLUTION DES M√âTRIQUES:")
        print("-" * 30)

        if len(self.metriques_evolution['confiance_moyenne']) > 1:
            confiances = self.metriques_evolution['confiance_moyenne']
            print(".2f")
            print(".2f")
            # Calculer l'√©cart-type manuellement
            moyenne = sum(confiances) / len(confiances)
            variance = sum((x - moyenne) ** 2 for x in confiances) / len(confiances)
            ecart_type = variance ** 0.5
            print(f"  ‚Ä¢ √âcart-type: {ecart_type:.3f}")

        # Recommandations
        print("\nüí° RECOMMANDATIONS:")
        print("-" * 20)

        if amelioration_totale > 0.1:
            print("  ‚Ä¢ üéØ Excellents r√©sultats ! Le syst√®me s'am√©liore bien")
            print("  ‚Ä¢ üìö Continuer l'entra√Ænement avec de nouvelles donn√©es")
            print("  ‚Ä¢ üî¨ Explorer de nouveaux types de puzzles")
        elif amelioration_totale > 0:
            print("  ‚Ä¢ ‚úÖ Am√©lioration mod√©r√©e obtenue")
            print("  ‚Ä¢ üìà Consid√©rer plus de cycles d'entra√Ænement")
            print("  ‚Ä¢ üéØ Ajuster les param√®tres d'optimisation")
        else:
            print("  ‚Ä¢ üîÑ Performance stable atteinte")
            print("  ‚Ä¢ ‚öôÔ∏è  Consid√©rer l'ajustement des strat√©gies")
            print("  ‚Ä¢ üß™ Tester de nouvelles approches d'entra√Ænement")

        print("\nüèÜ CONCLUSION:")
        print("-" * 15)
        print("  ‚Ä¢ Syst√®me d'entra√Ænement continu op√©rationnel")
        print("  ‚Ä¢ Capacit√© d'auto-am√©lioration d√©montr√©e")
        print("  ‚Ä¢ Base solide pour l'√©volution future √©tablie")

def main():
    """Fonction principale"""
    print("üèãÔ∏è  ENTRA√éNEMENT CONTINU DU SYST√àME ML ARC-AGI")
    print("Am√©lioration progressive des performances")
    print()

    entraineur = EntraineurContinu()
    resultats = entraineur.executer_entrainement_complet()

    print("\n" + "=" * 50)
    print("üèãÔ∏è  ENTRA√éNEMENT CONTINU TERMIN√â !")
    print("=" * 50)
    print("  ‚Ä¢ Syst√®me am√©lior√© par apprentissage it√©ratif")
    print("  ‚Ä¢ Performances optimis√©es et valid√©es")
    print("  ‚Ä¢ Base de connaissances enrichie")
    print("  ‚Ä¢ Pr√™t pour de nouveaux challenges")

if __name__ == "__main__":
    main()
